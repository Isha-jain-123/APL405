# -*- coding: utf-8 -*-
"""APL405_A2_P1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fZnF_FZfcNf4rfZ7kxD8BVr8nKnjUfQf
"""

# from google.colab import files
# uploaded = files.upload()

import numpy as np
import matplotlib.pyplot as plt

# data = np.loadtxt('prob1data.txt', delimiter=',')
# x = data[0]
# y = data[1]
# plt.plot(x, y,'o',markersize=2)
# plt.xlim([-1,5])
# plt.ylim([-12,12])

import random

class nlr:
  # Evaluates the gradient of cost function (J). Hint: You can use this to optimize w
  def grad(self,x,y,w):
    grad_J = []
    m = len(x)
    for i in range(2):
      p = 0
      for j in range(len(x)):
         p += (w[1]*(x[j]**2) + w[0] - y[j])*x[i]
      grad_J.append(p/m)
    return grad_J
    # m = x.shape[0]
    # grad_J = ((np.dot(x.T,np.dot(x,w.T) - y)).T)/m
    # return grad_J

  # This function calculates the cost (J)
  def computeCost(self,x,y,w):
    # J = [0.5*(hi-yi)**2 for i in range(len(x))]
    m = len(x)
    J = 0
    for i in range (len(x)):
      J += (w[1]*(x[i]**2) + w[0]-y[i])**2

    J = J*(1/(2*m))
    return J
    # J = 0
    # for i in range(x.shape[0]):
    #   J = J + ((w[1]*(x[i]**2) + w[0]-y[i])**2)/(2*x.shape[0])
    # return J


  # This function optimizes the weights w_0, w_1, w_2. Batch Gradient Descent method
  def BgradientDescent(self, x, y, w, alpha, iters):
    m = len(x)  # number of training examples
    w_orig = w.copy() # To keep a copy of original weights
    
    J_history = []   # Use a python list to save cost in every iteration

    for i in range(iters):
      # Loop to update weights (w vector)
      # Also save cost at every step
      w = np.array(w)
      w = w - alpha * np.array(self.grad(x,y,w))  # NOT SURE if we should use w or w_orig while calling grad fxn.
      J_history.append(self.computeCost(x,y,w))

    return w, J_history


    # This function optimizes the weights w_0, w_1, w_2. Stochastic Gradient Descent method
  def SgradientDescent(self, x, y, w, alpha, iters):
    m = len(x)   # number of training examples
    w_orig = w.copy() # To keep a copy of original weights
    
    J_history_s = []   # Use a python list to save cost in every iteration

    for i in range(iters):
      r = random.randint(0,m) # generate random integers (refer lab demo code)
      x_mini = x[:3*m//4] # create randomly a minibatch from whole data set and find weights based on that new data set.
      y_mini = y[:3*m//4]
      # Loop to update weights (w vector)
      # Also save cost at every step
      w = np.array(w)
      w = w - alpha * np.array(self.grad(x_mini,y_mini,w))  # NOT SURE if we should use w or w_orig while calling grad fxn.
      J_history_s.append(self.computeCost(x_mini,y_mini,w))

    return w, J_history_s


  # This function implements line search Secant method
  # refer to class notes on optimization and lab demo copy.

  def ls_secant(self,x,y,w,d):
    # d is search direction d = -grad(J). Refer class and Lab notes
    # d = np.array(-1*grad_J)
    epsilon = 10**(-4) # Line search tolerance
    
    alpha_curr = 0     # Alpha (x_i-1)
    alpha = 0.01       # initial value (x_i)

    # dphi_zero =  d.transpose()*grad_J[0]          # dphi_zero = (d^T)(grad J(w_0) # At every alpha updation loop you will have a given initial weight vector (w_0)
    # dphi_curr = dphi_zero  # required for first alpha iteration
    dphi_new = self.computeCost(x,y,w - alpha*np.array(self.grad(x,y,w))) 
    dphi_old = self.computeCost(x,y,w)
    old_diff = 0.0
    i = 0
    while abs(dphi_new - dphi_old) > (epsilon*abs(old_diff)):  # tolerance or looping criteria used here
      # write loop to update alpha
      old_diff = dphi_new - dphi_old
      alpha_latest = alpha + dphi_new*((dphi_new - dphi_old)/(alpha-alpha_curr))
      alpha_curr = alpha
      alpha = alpha_latest
      dphi_old = dphi_new
      dphi_new = self.computeCost(x,y,w - alpha*np.array(self.grad(x,y,w)))
    return alpha
  

  def AgradientDescent(self,x, y, w, iters):
    m = len(x)   # number of training examples
    w = w.copy() # To keep a copy of original weights
    eps = 10**(-12); # tolerance for J_history

    J_history_a = [0]   # Use a python list to save cost in every iteration

    for i in range(iters):
      d = -1*self.grad(x,y,w) # d is search direction d = -grad(J)
      alpha = self.ls_secant(x,y,w,d) # update alpha at every iteration

      w = w - alpha*np.array(self.grad(x,y,w)) 
      C = self.computeCost(x,y,w)    
      J_history_a.append(C) # Also save cost at every step in J_history_a
    
      # Loop to update weights (w vector)
      # Also save cost at every step in J_history_a
      # stopping criteria
      if (J_history_a[i+1] -J_history_a[i]) < eps:
        print('No. of iterations',i)
        break

    return w, J_history_a

'''
model = nlr()
# w = np.random.uniform(0,1,x.shape[1])
w = [1,1]
w,J_history_s = model.AgradientDescent(x, y, w, 50000)
# xarr = np.linspace(1,50000,50000)

plt.plot([i for i in range(50000)],J_history_s,'o')
plt.xlabel("No of iterations")
plt.ylabel("Cost function for Agd")

model = nlr()
# model.test()
alpha = [0.1, 0.5, 0.01, 0.05]
w = [1,1]
a,b = model.BgradientDescent(x, y, w, alpha[3] , 50000)
plt.plot(b,[i for i in range(50000)],'o',markersize=0.5)
  
# print(a)
# print(b)

model = nlr()
w = [1,1]
# print(w)
# model.test()
c,d = model.SgradientDescent(x, y, w, 0.01, 50000)
plt.plot([i for i in range(50000)],d,'o',markersize=0.5)
print(c)
print(d)

# w = np.random.uniform(0,1,x.shape[1])
w = [1,1]
model = nlr()
w,J_history_s = model.BgradientDescent(x, y, w,0.01, 50000)
plt.plot(data[0,:],data[1,:],'o')
plt.ylabel("Height")
plt.xlabel("Time")
#testing
x = np.linspace(0,2.5,1000).reshape((1000,1))
print(x.shape)

x_pred = []
for i in range(1000):
  x_pred.append(w[0]+w[1]*(x[i]**2))

# print(x[:,1])
plt.plot(x[:,0],x_pred,'o')
plt.ylabel("Height")
plt.xlabel("Time")
'''



